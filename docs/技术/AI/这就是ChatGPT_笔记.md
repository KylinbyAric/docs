# GPT在做什么？它为什么能做这些？
简单概括，GPT是在上下文的语境下，根据以往训练的结果，猜测下一个词是什么。比如“太阳下山了，天气变_”，GPT会根据以往结果，列出下一个词"凉"“冷”“低”的概率，根据概率高低选择词语。
这里就引出一个温度的概念，当温度为0时，GPT会选择概率最高的那一个，当温度为1时，GPT会最大程度随机地选择一个词。

# 概率从何而来？
如果按照字母来做随机做排序，那么哪怕生成一个简短的句子，计算量都是海量的，呈指数增长的，算力的增长很明显无法支撑。
概率来源于GPT的训练数据，GPT在训练过程中，会根据训练数据，生成一个概率分布，这个概率分布会决定GPT的生成结果。

# 什么是模型？
如果根据某一个模型，能够低成本地预测下一个词，那么这个模型就是GPT要做的事情。

# 神经网络
当我们在看到一个“2”的图像时，图像的光子会落到我们光感细胞里，它们会在神经细胞里产生电信号，每一层的电信号都传递给下一层。最终我们才形成“图像是2”的想法。
每一个神经元和下一个神经元的连接称为权重，权重越小，连接越弱，权重越大，连接越强。识别本质就是找到权重最"准确"的神经元组合。

训练的过程，就是给定成功的样例，让神经元不断调整权重，最终找到一个最准确的神经元组合，而这就是我们要找的模型。



